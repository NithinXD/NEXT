{
  "sections": [
    {
      "title": "Message Classification",
      "content": "The first step in our process is to determine whether a user's message requires previous conversation context to be properly understood.\n\nWe use Gemini to classify messages into:\n\n **Context-Dependent**: Messages that refer to previous conversations (e.g., \"Can I go for it if I have oily skin?\")\n\n **Standalone**: Messages that can be answered without context (e.g., \"What services do you offer?\")\n\nFor context-dependent messages, we activate our adaptive context retrieval system."
    },
    {
      "title": "Adaptive Window Selection",
      "content": "For context-dependent queries, we dynamically adjust the \"window\" of conversation history based on the characteristics of the current message.\n\n```python\ndef adjust_window_size(current_message, history_items):\n    \"\"\"Dynamically adjust the window size based on message characteristics\"\"\"\n    # Short follow-ups with pronouns get a smaller, more focused window\n    if len(current_message.split()) <= 5 and has_pronouns(current_message):\n        return 3\n    \n    # Messages with explicit references to previous conversations get a larger window\n    if has_reference_to_previous(current_message):\n        return min(10, len(history_items))\n        \n    # Default window size for regular queries\n    return 5\n```\n\n**Example:**\n* For \"Can I go for it if I have oily skin?\" → Small window (3 items)\n* For \"What services did you suggest for me and my uncle?\" → Larger window (up to 10 items)"
    },
    {
      "title": "Semantic Relevance Ranking",
      "content": "Once we have our initial window, we rank the history items by their semantic relevance to the current query.\n\n```python\ndef rank_history_by_relevance(current_message, history_items, max_items=5):\n    \"\"\"Rank conversation history items by semantic relevance to current query\"\"\"\n    # Get embedding for current message\n    query_embedding = get_embedding(current_message)\n    \n    # Calculate similarity scores\n    scored_items = []\n    for item in history_items:\n        # Combine user message and bot response\n        combined_text = f\"{item.message} {item.response}\"\n        item_embedding = get_embedding(combined_text)\n        \n        # Calculate similarity\n        similarity = cosine_similarity(query_embedding, item_embedding)\n        \n        # Apply recency factor (more recent items get a boost)\n        recency_factor = calculate_recency_factor(item.timestamp)\n        \n        # Final score combines similarity and recency\n        final_score = similarity * recency_factor\n        \n        scored_items.append((item, final_score))\n    \n    # Sort by score and return top items\n    scored_items.sort(key=lambda x: x[1], reverse=True)\n    return [item for item, score in scored_items[:max_items]]\n```\n\nThis hybrid approach ensures that we select history items that are both:\n\n **Semantically relevant** to the current query\n **Temporally relevant** (with a preference for recent conversations)"
    },
    {
      "title": "Pronoun Resolution !",
      "content": "This is the feature that resolves pronouns in follow-up questions. My solution using **Sliding Window Approach** and ranking the items with **Recency Score** and **Semantic Relevance Score** involves detecting pronouns, identifying the most recent conversation related to those pronouns, and mapping them appropriately. The combination of Recency Score and Semantic Relevance Score works for now but remains experimental and needs further refinement.\n This approach works when the follow up questions are unrelated and unique but with same follow up question the relevance beats recency. Tried tinkering with the weights and how Gemini should handle this ranking but still facing issues at certain times. Here's a visual representation of the process:\n\ngraph TD\n    A[Detect Pronouns] --> B{Is Short Follow-up?}\n    B -->|Yes| C[Prioritize Most Recent Conversation]\n    B -->|No| D[Use Semantic Ranking]\n    C --> E[Identify Main Topic in Recent Conversation]\n    E --> F[Map Pronoun to Main Topic]\n```\n\nFor messages like \"Can I go for it if I have oily skin?\", our system:\n\n1. Detects the pronoun \"it\"\n2. Identifies this as a short follow-up question\n3. Examines the most recent conversation (about body polish or aromatherapy massage)\n4. Maps \"it\" to the main topic/service in that conversation\n5. Provides a response about that specific service\n\n**Example Conversation Flow:**\n\n> **User:** What's body polish?  \n> **Bot:** A body polish is an exfoliating treatment that leaves your skin feeling smooth...\n>\n **User:** Can people with oily skin do it?  \n> **Bot:** Yes, our body polish is suitable for most skin types, including oily skin...\n>\n **User:** What is aromatherapy massage?  \n> **Bot:** Aromatherapy massage combines massage therapy with essential oils to promote relaxation...\n>\n **User:** Can I go for it if I have oily skin?  \n> **Bot:** Yes, aromatherapy massage is suitable for people with oily skin. In fact, certain essential oils like tea tree and lavender can be beneficial for oily skin...\n\nIn this example, the system correctly resolves the pronoun \"it\" in the final question to refer to \"aromatherapy massage\" (the most recent topic) rather than \"body polish\" (the earlier topic) but this is not always the case. The solution I have gone for right now for this problem is to use an **Sliding Windows Approach** and ranking the context items recieved with **Recency Score** and **Semantic Relevance Score**. This demonstrates how our system maintains context awareness even when the conversation shifts between multiple topics but still I get incorrect answers sometimes. My next approach is to build an **Topic Monitoring System** that can monitor the conversation flow and detect changes in topics and update the context accordingly."
    },
    {
      "title": "Long-term Memory Retrieval",
      "content": "Our system also maintains long-term memory of past conversations, allowing users to refer to topics discussed many messages ago.\n\n```python\ndef recall_semantic_memory(user_id, query, top_k=3):\n    \"\"\"Retrieve semantically similar past conversations\"\"\"\n    query_vec = get_embedding(query)\n    \n    # Search vector database for similar conversations\n    results = vector_db.search(\n        vector=query_vec,\n        filter={\"user_id\": user_id},\n        top_k=top_k\n    )\n    \n    return results\n```\n\n**Example:**\n\n> **User:** I have back pain. Can you suggest some massages for me and my uncle?\n>\n **Bot:** For back pain, I would suggest the Deep Tissue Massage, Aromatherapy Massage, or Hot Stone Massage. These are all designed to relax muscles and relieve tension...\n>\n [20+ messages later in a new session after signing out and signing back in]\n>\n **User:** What services did you suggest for me and my uncle?\n>\n **Bot:** For you and your uncle's back pain, I previously suggested the Deep Tissue Massage, Aromatherapy Massage, and Hot Stone Massage. Would you like to book any of these services?\n\nThis example demonstrates how our system:\n\n1. Recognizes references to past conversations\n2. Retrieves the semantically relevant memory about back pain treatments\n3. Provides a contextually appropriate response about the previously suggested massages"
    }
  ]
}